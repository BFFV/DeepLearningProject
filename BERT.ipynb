{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"17108037891642fd8535f898ffc1c666":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_454c54b5f7e34caabfcdfb3751647f1d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2e1db44876aa4bda8f432424d43ef49d","IPY_MODEL_d2057bb0a03148d89ff752025b209034"]}},"454c54b5f7e34caabfcdfb3751647f1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e1db44876aa4bda8f432424d43ef49d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_625f0bb8d61443ffa9aec2e2f52db015","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":443,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":443,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_658e95de041f4b6abbd70a8071253297"}},"d2057bb0a03148d89ff752025b209034":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_296fc3b5f35f49a4a8b71ba7450f39ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 443/443 [00:00&lt;00:00, 919B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f4a53ffb84641be966022b5f995d597"}},"625f0bb8d61443ffa9aec2e2f52db015":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"658e95de041f4b6abbd70a8071253297":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"296fc3b5f35f49a4a8b71ba7450f39ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0f4a53ffb84641be966022b5f995d597":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0325dd797ca640cea44dc5d2d50d3378":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a5d823c6c36f4ffaa54de63b7df27187","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bdec4b4708b1446bbeb00ddef16511c7","IPY_MODEL_183df2bf188a4f9fba59234e57b205e4"]}},"a5d823c6c36f4ffaa54de63b7df27187":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdec4b4708b1446bbeb00ddef16511c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_eb910005a7ae4e04ab28ac8d506e9f9c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1340675298,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1340675298,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b871a4177dba4977813c16a6a71d3b27"}},"183df2bf188a4f9fba59234e57b205e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3f1e67a35637482e9a2db7e7233d02c2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.34G/1.34G [00:22&lt;00:00, 58.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba7cd4be6dcb457db7197cd326a56793"}},"eb910005a7ae4e04ab28ac8d506e9f9c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b871a4177dba4977813c16a6a71d3b27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f1e67a35637482e9a2db7e7233d02c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba7cd4be6dcb457db7197cd326a56793":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"604df6fab59c46438be9ac909632e6fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_54decd45844c47ea8c2816ef729e7445","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9c50285033b941c19bb0d6cfefa35a92","IPY_MODEL_9cdafc71790e4a65afdea6267db7ea29"]}},"54decd45844c47ea8c2816ef729e7445":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c50285033b941c19bb0d6cfefa35a92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7773da342fd34ddd8d98d22308ff84a0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_15cf214d3f95421790d246a7fdc8d200"}},"9cdafc71790e4a65afdea6267db7ea29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2c9c2fd7eece41589d73d9a238225905","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 739kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c7052a47457d44e2b4914734294eb671"}},"7773da342fd34ddd8d98d22308ff84a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"15cf214d3f95421790d246a7fdc8d200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c9c2fd7eece41589d73d9a238225905":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c7052a47457d44e2b4914734294eb671":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"457VPa20fZzY"},"source":["# CÃ³digo ðŸš€\n","\n","Elegimos este cÃ³digo como guÃ­a para nuestro proyecto, en el que se implementa un finetunning del modelo Bert para el preprocesamiento de datos."]},{"cell_type":"markdown","metadata":{"id":"gVq-TuylYRDW"},"source":["## 1. Install huggingface transformers library"]},{"cell_type":"markdown","metadata":{"id":"f9nhy3PzGQ44"},"source":["This example uses the `transformers` [library](https://github.com/huggingface/transformers/) by huggingface. We'll start by installing the package."]},{"cell_type":"code","metadata":{"id":"aQl0MMrOGIup","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eca77275-3395-4688-d3b3-fd09ea480f95"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 32.2MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 27.0MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=e40f2d5824d381267e0eced74acb814af74263666f2ea7b0c6efc4f8f7fab010\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-ONLrgJK99TQ"},"source":["import torch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1WThOUtpYvG-"},"source":["## 2. Load Fine-Tuned BERT-large"]},{"cell_type":"code","metadata":{"id":"-Mnv95sX-U9K","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["17108037891642fd8535f898ffc1c666","454c54b5f7e34caabfcdfb3751647f1d","2e1db44876aa4bda8f432424d43ef49d","d2057bb0a03148d89ff752025b209034","625f0bb8d61443ffa9aec2e2f52db015","658e95de041f4b6abbd70a8071253297","296fc3b5f35f49a4a8b71ba7450f39ba","0f4a53ffb84641be966022b5f995d597","0325dd797ca640cea44dc5d2d50d3378","a5d823c6c36f4ffaa54de63b7df27187","bdec4b4708b1446bbeb00ddef16511c7","183df2bf188a4f9fba59234e57b205e4","eb910005a7ae4e04ab28ac8d506e9f9c","b871a4177dba4977813c16a6a71d3b27","3f1e67a35637482e9a2db7e7233d02c2","ba7cd4be6dcb457db7197cd326a56793"]},"outputId":"2744c594-ef24-437d-d158-956918c40a11"},"source":["from transformers import BertForQuestionAnswering\n","\n","model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17108037891642fd8535f898ffc1c666","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443.0, style=ProgressStyle(description_â€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0325dd797ca640cea44dc5d2d50d3378","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1340675298.0, style=ProgressStyle(descrâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SFQ5f7gv-RBH","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["604df6fab59c46438be9ac909632e6fa","54decd45844c47ea8c2816ef729e7445","9c50285033b941c19bb0d6cfefa35a92","9cdafc71790e4a65afdea6267db7ea29","7773da342fd34ddd8d98d22308ff84a0","15cf214d3f95421790d246a7fdc8d200","2c9c2fd7eece41589d73d9a238225905","c7052a47457d44e2b4914734294eb671"]},"outputId":"1d000603-9233-4321-9efb-6eb176ba228e"},"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"604df6fab59c46438be9ac909632e6fa","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I__1ubvcZYow"},"source":["## 3. Ask a Question"]},{"cell_type":"code","metadata":{"id":"kWzZP4EN-Zxg"},"source":["question = \"How many parameters does BERT-large have?\"\n","answer_text = \"BERT-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take a couple minutes to download to your Colab instance.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYoX33CfKGsr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14b9e3fe-5afc-46d8-e6fa-25d183674aff"},"source":["# Apply the tokenizer to the input text, treating them as a text-pair.\n","input_ids = tokenizer.encode(question, answer_text)\n","\n","print('The input has a total of {:} tokens.'.format(len(input_ids)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The input has a total of 70 tokens.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pNRVuaKSNFG8"},"source":["Just to see exactly what the tokenizer is doing, let's print out the tokens with their IDs."]},{"cell_type":"code","metadata":{"id":"Iow838yPNDTv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0ffb2a5f-fdae-43ca-b146-b1604cc8bab3"},"source":["# BERT only needs the token IDs, but for the purpose of inspecting the \n","# tokenizer's behavior, let's also get the token strings and display them.\n","tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","\n","# For each token and its id...\n","for token, id in zip(tokens, input_ids):\n","    \n","    # If this is the [SEP] token, add some space around it to make it stand out.\n","    if id == tokenizer.sep_token_id:\n","        print('')\n","    \n","    # Print the token string and its ID in two columns.\n","    print('{:<12} {:>6,}'.format(token, id))\n","\n","    if id == tokenizer.sep_token_id:\n","        print('')\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["[CLS]           101\n","how           2,129\n","many          2,116\n","parameters   11,709\n","does          2,515\n","bert         14,324\n","-             1,011\n","large         2,312\n","have          2,031\n","?             1,029\n","\n","[SEP]           102\n","\n","bert         14,324\n","-             1,011\n","large         2,312\n","is            2,003\n","really        2,428\n","big           2,502\n",".             1,012\n",".             1,012\n",".             1,012\n","it            2,009\n","has           2,038\n","24            2,484\n","-             1,011\n","layers        9,014\n","and           1,998\n","an            2,019\n","em            7,861\n","##bed         8,270\n","##ding        4,667\n","size          2,946\n","of            1,997\n","1             1,015\n",",             1,010\n","02            6,185\n","##4           2,549\n",",             1,010\n","for           2,005\n","a             1,037\n","total         2,561\n","of            1,997\n","340          16,029\n","##m           2,213\n","parameters   11,709\n","!               999\n","altogether   10,462\n","it            2,009\n","is            2,003\n","1             1,015\n",".             1,012\n","34            4,090\n","##gb         18,259\n",",             1,010\n","so            2,061\n","expect        5,987\n","it            2,009\n","to            2,000\n","take          2,202\n","a             1,037\n","couple        3,232\n","minutes       2,781\n","to            2,000\n","download      8,816\n","to            2,000\n","your          2,115\n","cola         15,270\n","##b           2,497\n","instance      6,013\n",".             1,012\n","\n","[SEP]           102\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uJ7PRx2dKqFN"},"source":["# Search the input_ids for the first instance of the `[SEP]` token.\n","sep_index = input_ids.index(tokenizer.sep_token_id)\n","\n","# The number of segment A tokens includes the [SEP] token istelf.\n","num_seg_a = sep_index + 1\n","\n","# The remainder are segment B.\n","num_seg_b = len(input_ids) - num_seg_a\n","\n","# Construct the list of 0s and 1s.\n","segment_ids = [0]*num_seg_a + [1]*num_seg_b\n","\n","# There should be a segment_id for every input token.\n","assert len(segment_ids) == len(input_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQiKr6Aw-YTg"},"source":["# Run our example through the model.\n","outputs = model(torch.tensor([input_ids]), # The tokens representing our input text.\n","                             token_type_ids=torch.tensor([segment_ids]), # The segment IDs to differentiate question from answer_text\n","                             return_dict=True) \n","\n","start_scores = outputs.start_logits\n","end_scores = outputs.end_logits\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LeUQ44hAJmn9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a060a6de-b02e-4aac-951b-cf4f29aa741d"},"source":["# Find the tokens with the highest `start` and `end` scores.\n","answer_start = torch.argmax(start_scores)\n","answer_end = torch.argmax(end_scores)\n","\n","# Combine the tokens in the answer and print it out.\n","answer = ' '.join(tokens[answer_start:answer_end+1])\n","\n","print('Answer: \"' + answer + '\"')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Answer: \"340 ##m\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Khral6HZXCuI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"10fd61d4-a74c-4015-daf9-38d5087cf3b0"},"source":["# Start with the first token.\n","answer = tokens[answer_start]\n","\n","# Select the remaining answer tokens and join them with whitespace.\n","for i in range(answer_start + 1, answer_end + 1):\n","    \n","    # If it's a subword token, then recombine it with the previous token.\n","    if tokens[i][0:2] == '##':\n","        answer += tokens[i][2:]\n","    \n","    # Otherwise, add a space then the token.\n","    else:\n","        answer += ' ' + tokens[i]\n","\n","print('Answer: \"' + answer + '\"')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Answer: \"340m\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8UyBYNmeegGf"},"source":["## 4. Examples"]},{"cell_type":"code","metadata":{"id":"rH8NbBlsfxZ_"},"source":["def answer_question(question, answer_text):\n","    '''\n","    Takes a `question` string and an `answer_text` string (which contains the\n","    answer), and identifies the words within the `answer_text` that are the\n","    answer. Prints them out.\n","    '''\n","    # ======== Tokenize ========\n","    # Apply the tokenizer to the input text, treating them as a text-pair.\n","    input_ids = tokenizer.encode(question, answer_text)\n","\n","    # Report how long the input sequence is.\n","    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n","\n","    # ======== Set Segment IDs ========\n","    # Search the input_ids for the first instance of the `[SEP]` token.\n","    sep_index = input_ids.index(tokenizer.sep_token_id)\n","\n","    # The number of segment A tokens includes the [SEP] token istelf.\n","    num_seg_a = sep_index + 1\n","\n","    # The remainder are segment B.\n","    num_seg_b = len(input_ids) - num_seg_a\n","\n","    # Construct the list of 0s and 1s.\n","    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n","\n","    # There should be a segment_id for every input token.\n","    assert len(segment_ids) == len(input_ids)\n","\n","    # ======== Evaluate ========\n","    # Run our example through the model.\n","    outputs = model(torch.tensor([input_ids]), # The tokens representing our input text.\n","                    token_type_ids=torch.tensor([segment_ids]), # The segment IDs to differentiate question from answer_text\n","                    return_dict=True) \n","\n","    start_scores = outputs.start_logits\n","    end_scores = outputs.end_logits\n","\n","    # ======== Reconstruct Answer ========\n","    # Find the tokens with the highest `start` and `end` scores.\n","    answer_start = torch.argmax(start_scores)\n","    answer_end = torch.argmax(end_scores)\n","\n","    # Get the string versions of the input tokens.\n","    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","\n","    # Start with the first token.\n","    answer = tokens[answer_start]\n","\n","    # Select the remaining answer tokens and join them with whitespace.\n","    for i in range(answer_start + 1, answer_end + 1):\n","        \n","        # If it's a subword token, then recombine it with the previous token.\n","        if tokens[i][0:2] == '##':\n","            answer += tokens[i][2:]\n","        \n","        # Otherwise, add a space then the token.\n","        else:\n","            answer += ' ' + tokens[i]\n","\n","    print('Answer: \"' + answer + '\"')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DVlKTK-njWrX"},"source":["As our reference text, I've taken the Abstract of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf).\n"]},{"cell_type":"code","metadata":{"id":"y4VPq6FdjxyX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c58d2447-6493-4dc1-f717-4f66a707d72a"},"source":["import textwrap\n","\n","# Wrap text to 80 characters.\n","wrapper = textwrap.TextWrapper(width=80) \n","\n","bert_abstract = \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspecific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\"\n","\n","print(wrapper.fill(bert_abstract))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["We introduce a new language representation model called BERT, which stands for\n","Bidirectional Encoder Representations from Transformers. Unlike recent language\n","representation models (Peters et al., 2018a; Radford et al., 2018), BERT is\n","designed to pretrain deep bidirectional representations from unlabeled text by\n","jointly conditioning on both left and right context in all layers. As a result,\n","the pre-trained BERT model can be finetuned with just one additional output\n","layer to create state-of-the-art models for a wide range of tasks, such as\n","question answering and language inference, without substantial taskspecific\n","architecture modifications. BERT is conceptually simple and empirically\n","powerful. It obtains new state-of-the-art results on eleven natural language\n","processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute\n","improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1\n","question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD\n","v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tEB654YCknYv"},"source":["-----------------------------\n","Ask BERT what its name stands for (the answer is in the first sentence of the abstract)."]},{"cell_type":"code","metadata":{"id":"wfntqRCBegGj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b92fae04-b47c-4d41-ab6a-534fee04aa8e"},"source":["question = \"What does the 'B' in BERT stand for?\"\n","\n","answer_question(question, bert_abstract)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Query has 258 tokens.\n","\n","Answer: \"bidirectional encoder representations from transformers\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B6HcijzxkTO9"},"source":["---------------------\n","Ask BERT about example applications of itself :)\n","\n","The answer to the question comes from this passage from the abstract: \n","\n","> \"...BERT model can be finetuned with just one additional output\n","layer to create state-of-the-art models for **a wide range of tasks, such as\n","question answering and language inference,** without substantial taskspecific\n","architecture modifications.\""]},{"cell_type":"code","metadata":{"id":"MVNVGN5-gI06","colab":{"base_uri":"https://localhost:8080/"},"outputId":"db986fa1-3237-4db4-de8e-3bf564bfe176"},"source":["question = \"What are some example applications of BERT?\"\n","\n","answer_question(question, bert_abstract)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Query has 255 tokens.\n","\n","Answer: \"question answering and language inference\"\n"],"name":"stdout"}]}]}